{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook groups tweets into conversations and groups the\n",
    "# conversations by company and saves this info in \"data/comp_cll_df.csv\"\n",
    "\n",
    "# You need to first download twcs.zip (the raw data file containing\n",
    "# all the tweets) from \n",
    "# https://www.kaggle.com/thoughtvector/customer-support-on-twitter/downloads/twcs.zip/10.\n",
    "# You may have to create a free Kaggle account to do this.\n",
    "# Extract twcs.csv to the data/ folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## importing modules\n",
    "\n",
    "%matplotlib notebook\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from shutil import rmtree\n",
    "from glob import glob\n",
    "from fnmatch import fnmatch\n",
    "from dill import load, dump\n",
    "from pprint import pprint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 7 columns):\n",
      "tweet_id                   1000 non-null int64\n",
      "author_id                  1000 non-null object\n",
      "inbound                    1000 non-null bool\n",
      "created_at                 1000 non-null object\n",
      "text                       1000 non-null object\n",
      "response_tweet_id          679 non-null object\n",
      "in_response_to_tweet_id    747 non-null float64\n",
      "dtypes: bool(1), float64(1), int64(1), object(4)\n",
      "memory usage: 47.9+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>inbound</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>response_tweet_id</th>\n",
       "      <th>in_response_to_tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 31 22:10:47 +0000 2017</td>\n",
       "      <td>@115712 I understand. I would like to assist y...</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 22:11:45 +0000 2017</td>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 22:08:27 +0000 2017</td>\n",
       "      <td>@sprintcare I have sent several private messag...</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 31 21:54:49 +0000 2017</td>\n",
       "      <td>@115712 Please send us a Private Message so th...</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 21:49:35 +0000 2017</td>\n",
       "      <td>@sprintcare I did.</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id   author_id  inbound                      created_at  \\\n",
       "0         1  sprintcare    False  Tue Oct 31 22:10:47 +0000 2017   \n",
       "1         2      115712     True  Tue Oct 31 22:11:45 +0000 2017   \n",
       "2         3      115712     True  Tue Oct 31 22:08:27 +0000 2017   \n",
       "3         4  sprintcare    False  Tue Oct 31 21:54:49 +0000 2017   \n",
       "4         5      115712     True  Tue Oct 31 21:49:35 +0000 2017   \n",
       "\n",
       "                                                text response_tweet_id  \\\n",
       "0  @115712 I understand. I would like to assist y...                 2   \n",
       "1      @sprintcare and how do you propose we do that               NaN   \n",
       "2  @sprintcare I have sent several private messag...                 1   \n",
       "3  @115712 Please send us a Private Message so th...                 3   \n",
       "4                                 @sprintcare I did.                 4   \n",
       "\n",
       "   in_response_to_tweet_id  \n",
       "0                      3.0  \n",
       "1                      1.0  \n",
       "2                      4.0  \n",
       "3                      5.0  \n",
       "4                      6.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## read in data\n",
    "\n",
    "df_raw = pd.read_csv('data/twcs.csv', nrows=1000)\n",
    "print(df_raw.info())\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## clean data a bit and SAVE\n",
    "\n",
    "# convert 'created_at' to datetime format\n",
    "df = df_raw[['created_at', 'author_id', 'text', 'tweet_id', 'response_tweet_id', \n",
    "         'in_response_to_tweet_id', 'inbound']].copy()\n",
    "df['time'] = pd.to_datetime(df['created_at'], infer_datetime_format=True)\n",
    "\n",
    "# rearrange columns and sort by time\n",
    "df = df[['time', 'author_id', 'text', 'tweet_id', 'response_tweet_id', \n",
    "         'in_response_to_tweet_id', 'inbound']]\n",
    "df.sort_values(by = \"time\", inplace = True)\n",
    "\n",
    "# set tweet_id as index\n",
    "df.set_index('tweet_id', inplace = True)\n",
    "\n",
    "# standardize whitespace to avoid problems with saving as csv\n",
    "df[\"text\"] = df[\"text\"].str.replace(r\"\\s+\", \" \", regex = True)\n",
    "\n",
    "# save\n",
    "df.to_csv(\"data/twcs_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1000 entries, 348 to 276\n",
      "Data columns (total 6 columns):\n",
      "time                       1000 non-null datetime64[ns]\n",
      "author_id                  1000 non-null object\n",
      "text                       1000 non-null object\n",
      "response_tweet_id          679 non-null object\n",
      "in_response_to_tweet_id    747 non-null float64\n",
      "inbound                    1000 non-null bool\n",
      "dtypes: bool(1), datetime64[ns](1), float64(1), object(3)\n",
      "memory usage: 47.9+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>author_id</th>\n",
       "      <th>text</th>\n",
       "      <th>response_tweet_id</th>\n",
       "      <th>in_response_to_tweet_id</th>\n",
       "      <th>inbound</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>2011-08-29 03:20:05</td>\n",
       "      <td>115798</td>\n",
       "      <td>Lost your booking number? No worries, just dro...</td>\n",
       "      <td>349,350,351,352,347,353,354,355,356,357,358,35...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>2016-08-06 01:31:50</td>\n",
       "      <td>115818</td>\n",
       "      <td>@DELTA i booked my flight using delta amex car...</td>\n",
       "      <td>609</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>2016-08-06 01:44:03</td>\n",
       "      <td>Delta</td>\n",
       "      <td>@115818 Glad to check. Pls, DM your confirmati...</td>\n",
       "      <td>610</td>\n",
       "      <td>611.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>2017-10-12 10:11:50</td>\n",
       "      <td>115867</td>\n",
       "      <td>@AppleSupport my Apple TV works fine with my p...</td>\n",
       "      <td>751</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>2017-10-18 14:07:45</td>\n",
       "      <td>115769</td>\n",
       "      <td>Whoa! Come along with Lightroomâ€™s own Ben Ward...</td>\n",
       "      <td>292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        time author_id  \\\n",
       "tweet_id                                 \n",
       "348      2011-08-29 03:20:05    115798   \n",
       "611      2016-08-06 01:31:50    115818   \n",
       "609      2016-08-06 01:44:03     Delta   \n",
       "752      2017-10-12 10:11:50    115867   \n",
       "293      2017-10-18 14:07:45    115769   \n",
       "\n",
       "                                                       text  \\\n",
       "tweet_id                                                      \n",
       "348       Lost your booking number? No worries, just dro...   \n",
       "611       @DELTA i booked my flight using delta amex car...   \n",
       "609       @115818 Glad to check. Pls, DM your confirmati...   \n",
       "752       @AppleSupport my Apple TV works fine with my p...   \n",
       "293       Whoa! Come along with Lightroomâ€™s own Ben Ward...   \n",
       "\n",
       "                                          response_tweet_id  \\\n",
       "tweet_id                                                      \n",
       "348       349,350,351,352,347,353,354,355,356,357,358,35...   \n",
       "611                                                     609   \n",
       "609                                                     610   \n",
       "752                                                     751   \n",
       "293                                                     292   \n",
       "\n",
       "          in_response_to_tweet_id  inbound  \n",
       "tweet_id                                    \n",
       "348                           NaN     True  \n",
       "611                           NaN     True  \n",
       "609                         611.0    False  \n",
       "752                           NaN     True  \n",
       "293                           NaN     True  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### ENTRY POINT. load clean csv\n",
    "\n",
    "df = pd.read_csv('data/twcs_clean.csv').set_index(\"tweet_id\")\n",
    "df[\"time\"] = pd.to_datetime(df[\"time\"], infer_datetime_format=True)\n",
    "print(df.info())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing convo_start_locs ...\n",
      "Total convos = 253\n",
      "\n",
      "Example convo for \"sprintcare\":\n",
      "[['@115714 yâ€™all lie about your â€œgreatâ€ connection. 5 bars LTE, still wonâ€™t load something. Smh.']\n",
      " [\"@115713 H there! We'd definitely like to work with you on this, how long have you been experiencing this issue? -AA\"]\n",
      " ['@sprintcare Since I signed up with you....Since day 1']\n",
      " [\"@115713 We understand your concerns and we'd like for you to please send us a Direct Message, so that we can further assist you. -AA\"]\n",
      " ['@sprintcare You gonna magically change your connectivity for me and my whole family ? ðŸ¤¥ ðŸ’¯']\n",
      " ['@115713 This is saddening to hear. Please shoot us a DM, so that we can look into this for you. -KC']]\n"
     ]
    }
   ],
   "source": [
    "## make tweet chains for individual conversations\n",
    "\n",
    "# save start_locs of convos\n",
    "# a convo starts when 'in_response_to' is nan\n",
    "def is_start_of_convo(rowtuple):\n",
    "    \n",
    "    # having a finite \"in_response_to_tweet_id\" \n",
    "    # means tweet is not convo starter\n",
    "    if np.isfinite(\n",
    "        getattr(rowtuple, \"in_response_to_tweet_id\")):\n",
    "        return False\n",
    "    \n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "def get_start_locs(df = df):\n",
    "    \n",
    "    print(\"Computing convo_start_locs ...\")\n",
    "    \n",
    "    # get the starter tups\n",
    "    starter_tups_map = filter(is_start_of_convo,\n",
    "                             df.itertuples())\n",
    "    \n",
    "    # get the locs of the starter tups\n",
    "    tup_to_loc = lambda tup: tup.Index\n",
    "    start_locs = list(map(tup_to_loc, starter_tups_map))\n",
    "    \n",
    "    return start_locs\n",
    "    \n",
    "convo_start_locs = get_start_locs()\n",
    "        \n",
    "print('Total convos =', len(convo_start_locs))\n",
    "# print('convo_start_locs =', convo_start_locs)\n",
    "\n",
    "# get the locs (and company) for a conversation given a start_loc\n",
    "def get_convo_locs_n_comp(convo_start_loc, df = df):\n",
    "    \n",
    "    def get_next_locs(cur_locs, df = df):\n",
    "        # recursively gets next locs\n",
    "        \n",
    "        next_locs = []\n",
    "        for cur_loc in cur_locs:\n",
    "            \n",
    "            if cur_loc in df.index:\n",
    "                resp_tw_ids_entry = df.loc[cur_loc]['response_tweet_id']\n",
    "                \n",
    "                if isinstance(resp_tw_ids_entry, str):\n",
    "                    # next line splits up something like \"45,65\"\n",
    "                    # in the response_tweet_id into a list of locs: [45, 65]\n",
    "                    next_locs += list(map(int, resp_tw_ids_entry.split(\",\")))\n",
    "                    \n",
    "        if len(next_locs) > 0:\n",
    "            next_locs += get_next_locs(next_locs)\n",
    "        \n",
    "        return next_locs\n",
    "    \n",
    "    convo_locs = [convo_start_loc] + get_next_locs([convo_start_loc])\n",
    "    \n",
    "    # take out non-existent locs\n",
    "    convo_locs = list(filter(\n",
    "        lambda loc: loc in df.index,\n",
    "        convo_locs\n",
    "        ))\n",
    "    \n",
    "    # make df and sort by time\n",
    "    convo_df = df.loc[convo_locs]\n",
    "    convo_df.sort_values(by = 'time', inplace = True)\n",
    "    convo_locs = list(convo_df.index)\n",
    "    \n",
    "    # get company\n",
    "    company = np.nan\n",
    "    for rowtup in convo_df.itertuples():\n",
    "\n",
    "        try:\n",
    "            # if int, keep hunting\n",
    "            _ = int(getattr(rowtup, \"author_id\"))\n",
    "            \n",
    "        except:\n",
    "            # if not int, save\n",
    "            company = getattr(rowtup, \"author_id\")\n",
    "            break\n",
    "    \n",
    "    return convo_locs, company\n",
    "\n",
    "start_loc = 18\n",
    "convo_locs, company = get_convo_locs_n_comp(start_loc)\n",
    "print(\"\\nExample convo for \\\"\" + company + \"\\\":\")\n",
    "# print(df.loc[convo_locs][[\"author_id\", \"time\", \"text\"]])\n",
    "\n",
    "# temporary\n",
    "print(df.loc[convo_locs][[\"text\"]].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[([348,\n",
      "   347,\n",
      "   343,\n",
      "   334,\n",
      "   344,\n",
      "   375,\n",
      "   374,\n",
      "   332,\n",
      "   333,\n",
      "   335,\n",
      "   336,\n",
      "   337,\n",
      "   338,\n",
      "   339,\n",
      "   340,\n",
      "   341,\n",
      "   342],\n",
      "  'AirAsiaSupport'),\n",
      " ([611, 609, 610], 'Delta'),\n",
      " ([752, 751, 750], 'AppleSupport'),\n",
      " ([293, 292, 291], 'AdobeCare'),\n",
      " ([614, 612, 613], 'McDonalds')]\n",
      " ...\n"
     ]
    }
   ],
   "source": [
    "## SLOW! get convo_loc_lists for all start_locs\n",
    "\n",
    "# cll: convo_loc_list\n",
    "cll_comp_tups = list(map(get_convo_locs_n_comp, convo_start_locs))\n",
    "pprint(cll_comp_tups[:5])\n",
    "print(\" ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list,\n",
       "            {'AirAsiaSupport': [[348,\n",
       "               347,\n",
       "               343,\n",
       "               334,\n",
       "               344,\n",
       "               375,\n",
       "               374,\n",
       "               332,\n",
       "               333,\n",
       "               335,\n",
       "               336,\n",
       "               337,\n",
       "               338,\n",
       "               339,\n",
       "               340,\n",
       "               341,\n",
       "               342],\n",
       "              [371, 369, 370, 368],\n",
       "              [367, 366, 364, 362, 363, 365]],\n",
       "             'Delta': [[611, 609, 610],\n",
       "              [801, 799, 796, 794, 795, 797, 798],\n",
       "              [814, 813, 811, 810, 809, 807, 808, 804, 805, 806],\n",
       "              [817,\n",
       "               815,\n",
       "               816,\n",
       "               818,\n",
       "               819,\n",
       "               820,\n",
       "               821,\n",
       "               833,\n",
       "               832,\n",
       "               847,\n",
       "               823,\n",
       "               822,\n",
       "               829,\n",
       "               834,\n",
       "               828,\n",
       "               835,\n",
       "               827,\n",
       "               826,\n",
       "               825,\n",
       "               824,\n",
       "               831,\n",
       "               830,\n",
       "               836,\n",
       "               839,\n",
       "               837,\n",
       "               838,\n",
       "               840,\n",
       "               843,\n",
       "               842,\n",
       "               841,\n",
       "               844,\n",
       "               846,\n",
       "               845],\n",
       "              [803, 802],\n",
       "              [792, 790, 791, 793]],\n",
       "             'AppleSupport': [[752, 751, 750],\n",
       "              [747, 746, 745, 744, 740, 738, 739, 741, 742, 743],\n",
       "              [765, 764, 763, 761, 760, 759],\n",
       "              [730, 729, 728, 727, 725, 724],\n",
       "              [756, 755, 754, 753],\n",
       "              [711, 710, 709, 708, 707, 705, 704, 703, 702, 701],\n",
       "              [719, 718, 717, 716],\n",
       "              [749, 748],\n",
       "              [767, 766],\n",
       "              [758, 757],\n",
       "              [723, 722, 721, 720],\n",
       "              [733, 732],\n",
       "              [700, 698, 696, 697, 699],\n",
       "              [736, 734, 735, 737],\n",
       "              [714, 712, 713]],\n",
       "             'AdobeCare': [[293, 292, 291],\n",
       "              [290, 289, 288, 287, 285, 284],\n",
       "              [283, 282],\n",
       "              [279, 278],\n",
       "              [281, 280],\n",
       "              [253,\n",
       "               251,\n",
       "               252,\n",
       "               254,\n",
       "               255,\n",
       "               256,\n",
       "               257,\n",
       "               258,\n",
       "               259,\n",
       "               260,\n",
       "               261,\n",
       "               262,\n",
       "               264,\n",
       "               268,\n",
       "               263,\n",
       "               266,\n",
       "               265,\n",
       "               267],\n",
       "              [295, 294],\n",
       "              [298, 296, 297, 300, 301, 299],\n",
       "              [250, 249, 247, 245, 242, 240, 241, 243, 244]],\n",
       "             'McDonalds': [[614, 612, 613],\n",
       "              [409, 410, 408, 487, 599, 598, 407]],\n",
       "             'sprintcare': [[1304, 1303, 1302],\n",
       "              [18, 17, 16, 15, 12, 11],\n",
       "              [8, 6, 5, 4, 3, 1, 2],\n",
       "              [20, 19],\n",
       "              [1312, 1311],\n",
       "              [1288, 1285, 1287, 1286, 1289, 1290],\n",
       "              [1299, 1300, 1298],\n",
       "              [1293, 1296, 1291, 1292, 1294, 1295]],\n",
       "             'ChipotleTweets': [[156, 155, 154],\n",
       "              [81, 80, 79],\n",
       "              [1346, 1345, 1344],\n",
       "              [163, 162, 161, 160],\n",
       "              [76, 75, 74, 73],\n",
       "              [175, 174, 172, 171, 170],\n",
       "              [177, 176],\n",
       "              [169, 168],\n",
       "              [167, 166],\n",
       "              [165, 164],\n",
       "              [159, 158],\n",
       "              [153, 152],\n",
       "              [78, 77],\n",
       "              [71, 70],\n",
       "              [69, 68],\n",
       "              [66, 64, 65],\n",
       "              [1421, 1420],\n",
       "              [1418, 1416, 1417, 1419],\n",
       "              [1408, 1407],\n",
       "              [1405, 1404],\n",
       "              [1403, 1402],\n",
       "              [1401, 1399, 1400],\n",
       "              [1398, 1397],\n",
       "              [1394, 1392, 1393, 1395],\n",
       "              [1386, 1384, 1385, 1387],\n",
       "              [1391, 1390],\n",
       "              [1380, 1378, 1379, 1381, 1382, 1383],\n",
       "              [1377, 1376],\n",
       "              [1375, 1374],\n",
       "              [1373, 1372],\n",
       "              [1371, 1370],\n",
       "              [1369, 1368],\n",
       "              [1367, 1366],\n",
       "              [1364, 1363],\n",
       "              [1361, 1359, 1360, 1362],\n",
       "              [1356, 1355],\n",
       "              [1354, 1353],\n",
       "              [1343, 1342],\n",
       "              [1341, 1340],\n",
       "              [1339, 1338],\n",
       "              [1336, 1334, 1335, 1337],\n",
       "              [1333, 1331, 1332],\n",
       "              [1330, 1329],\n",
       "              [1328, 1327],\n",
       "              [1358, 1357]],\n",
       "             'DropboxSupport': [[1559, 1558],\n",
       "              [1557, 1555, 1554],\n",
       "              [1563, 1562, 1561, 1560]],\n",
       "             'hulu_support': [[1279, 1278, 1277],\n",
       "              [1272, 1271, 1270, 1269, 1267, 1265, 1266, 1268],\n",
       "              [1264, 1263],\n",
       "              [1260, 1258, 1259, 1261, 1262],\n",
       "              [1275, 1273, 1274, 1276]],\n",
       "             'TMobileHelp': [[1072, 1071, 1070, 1069, 1068, 1067, 1066],\n",
       "              [1174, 1173, 1172, 1171, 1170, 1168, 1167, 1166],\n",
       "              [1158, 1157, 1156],\n",
       "              [1165, 1164],\n",
       "              [1161, 1160],\n",
       "              [1163, 1162]],\n",
       "             'AmazonHelp': [[662, 661, 660],\n",
       "              [643, 642, 641, 640, 639, 638, 637],\n",
       "              [682, 681, 680],\n",
       "              [678, 677, 676, 675],\n",
       "              [672, 671, 670, 668, 669],\n",
       "              [695, 694],\n",
       "              [630, 628, 626, 627, 629],\n",
       "              [632, 631],\n",
       "              [634, 633],\n",
       "              [646, 644, 645, 647],\n",
       "              [690, 689, 686, 684, 685, 687],\n",
       "              [664, 663],\n",
       "              [659, 658, 657, 656],\n",
       "              [636, 635],\n",
       "              [693, 692],\n",
       "              [667, 665, 666],\n",
       "              [652, 650, 651, 653, 654, 655],\n",
       "              [624, 622, 623, 625],\n",
       "              [617, 615, 616, 618, 619],\n",
       "              [649, 648],\n",
       "              [621, 620],\n",
       "              [325, 324],\n",
       "              [272, 269, 270, 271, 273, 274, 275]],\n",
       "             'British_Airways': [[886, 884, 883, 881, 880],\n",
       "              [969, 967, 968, 970],\n",
       "              [974, 971, 973, 972, 975, 976, 977, 979, 978],\n",
       "              [966, 965],\n",
       "              [872, 867, 868, 871, 869, 870, 873],\n",
       "              [877, 875, 876]],\n",
       "             'SouthwestAir': [[1239,\n",
       "               1238,\n",
       "               1237,\n",
       "               1236,\n",
       "               1235,\n",
       "               1234,\n",
       "               1233,\n",
       "               1232,\n",
       "               1231,\n",
       "               1230],\n",
       "              [1244, 1243],\n",
       "              [1242, 1241],\n",
       "              [1223, 1221, 1222, 1219, 1217, 1218, 1220],\n",
       "              [1216, 1215],\n",
       "              [1229, 1228],\n",
       "              [1214, 1213],\n",
       "              [1212, 1211]],\n",
       "             'UPSHelp': [[608, 607, 606], [605, 604]],\n",
       "             'AskAmex': [[406, 405, 404, 403, 399, 397, 398, 400, 401, 402]],\n",
       "             'sainsburys': [[1325, 1324]],\n",
       "             'CoxHelp': [[1513, 1511, 1510, 1509],\n",
       "              [1518, 1516, 1517, 1519],\n",
       "              [1515, 1514],\n",
       "              [1508, 1506, 1507],\n",
       "              [1521, 1520]],\n",
       "             'ATVIAssist': [[234, 232, 231, 226, 224, 225, 227, 228, 229, 230],\n",
       "              [239, 238],\n",
       "              [220, 219],\n",
       "              [216, 215, 213, 211, 212, 214],\n",
       "              [218, 217],\n",
       "              [210, 209],\n",
       "              [237, 235, 236]],\n",
       "             'VirginTrains': [[1207,\n",
       "               1206,\n",
       "               1205,\n",
       "               1204,\n",
       "               1203,\n",
       "               1202,\n",
       "               1201,\n",
       "               1200,\n",
       "               1199,\n",
       "               1198],\n",
       "              [1189, 1194, 1188, 1208, 1209, 1186, 1187],\n",
       "              [1182, 1181],\n",
       "              [1185, 1183, 1184],\n",
       "              [1180, 1178, 1179],\n",
       "              [1177, 1176]],\n",
       "             'AskPlayStation': [[188, 187],\n",
       "              [185, 184, 183, 182],\n",
       "              [180, 178, 179],\n",
       "              [1476, 1475],\n",
       "              [1474, 1473, 1472],\n",
       "              [1466, 1463, 1465, 1464],\n",
       "              [1458, 1457],\n",
       "              [1460, 1459],\n",
       "              [1456, 1454, 1452, 1453, 1455],\n",
       "              [1451, 1450],\n",
       "              [1471, 1470, 1469, 1468],\n",
       "              [1478, 1477],\n",
       "              [1462, 1461]],\n",
       "             'AskeBay': [[1553, 1551, 1550, 1549],\n",
       "              [1525,\n",
       "               1522,\n",
       "               1523,\n",
       "               1524,\n",
       "               1526,\n",
       "               1527,\n",
       "               1528,\n",
       "               1529,\n",
       "               1530,\n",
       "               1531,\n",
       "               1537,\n",
       "               1536,\n",
       "               1535,\n",
       "               1534,\n",
       "               1533,\n",
       "               1532,\n",
       "               1539,\n",
       "               1538,\n",
       "               1541,\n",
       "               1540],\n",
       "              [1544, 1542, 1543, 1545, 1546, 1547],\n",
       "              [1249,\n",
       "               1247,\n",
       "               1248,\n",
       "               1250,\n",
       "               1251,\n",
       "               1252,\n",
       "               1253,\n",
       "               1254,\n",
       "               1255,\n",
       "               1256,\n",
       "               1257],\n",
       "              [1246, 1245],\n",
       "              [1226, 1224, 1225, 1227]],\n",
       "             'YahooCare': [[601, 600]],\n",
       "             'AskPayPal': [[1449, 1448, 1447],\n",
       "              [1443, 1441, 1442, 1444, 1445, 1446],\n",
       "              [1436, 1435],\n",
       "              [1438, 1437],\n",
       "              [1440, 1439],\n",
       "              [1434, 1433],\n",
       "              [1432, 1431]],\n",
       "             'marksandspencer': [[198, 194, 196, 197, 195, 199, 200],\n",
       "              [193, 192],\n",
       "              [191, 190],\n",
       "              [202, 201]],\n",
       "             'Tesco': [[789, 788, 786, 785]],\n",
       "             'SpotifyCares': [[855, 854, 853, 852, 850, 848, 849, 851],\n",
       "              [862, 860, 858, 856, 857, 859],\n",
       "              [866, 865, 864, 863]],\n",
       "             'XboxSupport': [[323, 321, 322],\n",
       "              [318, 311, 309, 310, 312, 313, 314, 315, 317, 316],\n",
       "              [320, 319],\n",
       "              [277, 276]],\n",
       "             'HPSupport': [[1488, 1489, 1487],\n",
       "              [1485, 1484],\n",
       "              [1480, 1481, 1479]],\n",
       "             'VerizonSupport': [[59, 58, 57, 56, 55, 54, 53, 52, 51, 50],\n",
       "              [49, 48, 47, 46, 42, 40, 41, 43, 44, 45],\n",
       "              [63, 62],\n",
       "              [61, 60],\n",
       "              [36, 34, 35, 37],\n",
       "              [39, 38],\n",
       "              [1430, 1429],\n",
       "              [1428, 1427],\n",
       "              [1424, 1422, 1423, 1426, 1425]],\n",
       "             'VirginAtlantic': [[1569, 1568, 1567, 1566], [1565, 1564]],\n",
       "             'MicrosoftHelps': [[208, 207], [205, 203, 204]],\n",
       "             'ChaseSupport': [[1505, 1504, 1502, 1501, 1500, 1499, 1498],\n",
       "              [1495, 1494],\n",
       "              [1497, 1496],\n",
       "              [1492, 1490, 1493, 1491]],\n",
       "             'Ask_Spectrum': [[1321, 1319, 1318, 1317, 1316, 1315],\n",
       "              [29, 28, 24, 21, 23, 22, 25, 26, 27],\n",
       "              [31, 30],\n",
       "              [33, 32],\n",
       "              [1323, 1322],\n",
       "              [1314, 1313]],\n",
       "             'Morrisons': [[389, 390, 388],\n",
       "              [385, 383, 384, 386, 387],\n",
       "              [378, 376, 377, 379, 380, 381, 382]],\n",
       "             'NikeSupport': [[395, 396, 394, 393, 392]],\n",
       "             'Uber_Support': [[782, 781, 780, 778, 779],\n",
       "              [777, 776],\n",
       "              [775, 774],\n",
       "              [773, 772],\n",
       "              [784, 783],\n",
       "              [771, 768, 769, 770]],\n",
       "             'AirbnbHelp': [[306, 305, 304, 303], [308, 307]],\n",
       "             'AmericanAir': [[1000, 999, 998, 997, 996],\n",
       "              [1062, 1061],\n",
       "              [1065, 1064],\n",
       "              [1005, 1003, 1004, 1006],\n",
       "              [1009, 1008],\n",
       "              [1002, 1001]],\n",
       "             'nationalrailenq': [[331, 330, 329, 328, 327, 326]],\n",
       "             'AskLyft': [[603, 602]],\n",
       "             'BofA_Help': [[1575, 1574, 1573], [1571, 1572, 1570]],\n",
       "             'comcastcares': [[989, 987, 988, 990, 991, 992],\n",
       "              [982, 980, 981],\n",
       "              [994, 993],\n",
       "              [985, 986, 983, 984]],\n",
       "             'GWRHelp': [[1283, 1281, 1282, 1284]]})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### group convos by company\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "# making a dict where item is (company: clll)\n",
    "# clll: cll_list i.e. list of conversations (\"cll\"s)\n",
    "\n",
    "comp_clll_dict = defaultdict(list)\n",
    "\n",
    "for cll, comp in cll_comp_tups:\n",
    "    comp_clll_dict[comp].append(cll)\n",
    "    \n",
    "comp_clll_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comp_cll_df to csv:\n",
      "          company                                           clll_str\n",
      "0  AirAsiaSupport  348,347,343,334,344,375,374,332,333,335,336,33...\n",
      "1           Delta  611,609,610 801,799,796,794,795,797,798 814,81...\n",
      "2    AppleSupport  752,751,750 747,746,745,744,740,738,739,741,74...\n",
      "3       AdobeCare  293,292,291 290,289,288,287,285,284 283,282 27...\n",
      "4       McDonalds            614,612,613 409,410,408,487,599,598,407\n"
     ]
    }
   ],
   "source": [
    "### tool to save comp_clll_dict to csv\n",
    "\n",
    "def save_locs_dict_to_csv(comp_clll_dict = comp_clll_dict):\n",
    "    \n",
    "    # [[1, 2], [3, 4, 5]] to \"1,2 3,4,5\"\n",
    "    def list_list_to_str(ll):\n",
    "        return \" \".join(\n",
    "            [\",\".join(list(map(str, l)))\n",
    "                for l in ll]\n",
    "            )\n",
    "        \n",
    "    clls_map = comp_clll_dict.values()\n",
    "#     cll = list(comp_clll_dict.values())[0]\n",
    "#     print()\n",
    "    \n",
    "    cll_strs = list(map(list_list_to_str, clls_map))\n",
    "    \n",
    "    # make df\n",
    "    comp_cll_df = pd.DataFrame({\n",
    "        \"company\": list(comp_clll_dict.keys()),\n",
    "        \"clll_str\": cll_strs\n",
    "        })\n",
    "    \n",
    "    comp_cll_df.to_csv(\"data/comp_cll_df.csv\", index = False)\n",
    "    \n",
    "    return \"data/comp_cll_df.csv\"\n",
    "\n",
    "print(\"comp_cll_df to csv:\")\n",
    "print(pd.read_csv(save_locs_dict_to_csv()).head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comp_clll_dict_len:\n",
      "43\n"
     ]
    }
   ],
   "source": [
    "### ENTRY POINT. tool to load comp_clll_dict from csv\n",
    "\n",
    "def load_locs_dict_from_csv(path = \"data/comp_cll_df.csv\"):\n",
    "    \n",
    "    # \"1,2 3,4,5\" to [[1, 2], [3, 4, 5]]\n",
    "    def str_to_ll(s):\n",
    "        clstrs = s.split(\" \")\n",
    "        cll = [s.split(\",\") for s in clstrs]\n",
    "        return cll\n",
    "    \n",
    "    # read csv\n",
    "    df = pd.read_csv(path)\n",
    "    comps = df[\"company\"].values\n",
    "    clll_strs = df[\"clll_str\"]\n",
    "    cllls_map = map(str_to_ll, clll_strs)\n",
    "    \n",
    "    # turn to dict\n",
    "    comp_clll_dict = dict(zip(\n",
    "        comps, cllls_map\n",
    "        ))\n",
    "    return comp_clll_dict\n",
    "\n",
    "comp_clll_dict = load_locs_dict_from_csv()\n",
    "print(\"comp_clll_dict_len:\")\n",
    "pprint(len(comp_clll_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "twitt_cust_serv",
   "language": "python",
   "name": "twitt_cust_serv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
