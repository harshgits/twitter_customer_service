{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## importing modules\n",
    "\n",
    "%matplotlib notebook\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from shutil import rmtree\n",
    "from glob import glob\n",
    "from fnmatch import fnmatch\n",
    "from dill import load, dump\n",
    "from pprint import pprint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2811774 entries, 0 to 2811773\n",
      "Data columns (total 7 columns):\n",
      "tweet_id                   int64\n",
      "author_id                  object\n",
      "inbound                    bool\n",
      "created_at                 object\n",
      "text                       object\n",
      "response_tweet_id          object\n",
      "in_response_to_tweet_id    float64\n",
      "dtypes: bool(1), float64(1), int64(1), object(4)\n",
      "memory usage: 131.4+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>inbound</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>response_tweet_id</th>\n",
       "      <th>in_response_to_tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 31 22:10:47 +0000 2017</td>\n",
       "      <td>@115712 I understand. I would like to assist y...</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 22:11:45 +0000 2017</td>\n",
       "      <td>@sprintcare and how do you propose we do that</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 22:08:27 +0000 2017</td>\n",
       "      <td>@sprintcare I have sent several private messag...</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>sprintcare</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 31 21:54:49 +0000 2017</td>\n",
       "      <td>@115712 Please send us a Private Message so th...</td>\n",
       "      <td>3</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>115712</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 31 21:49:35 +0000 2017</td>\n",
       "      <td>@sprintcare I did.</td>\n",
       "      <td>4</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id   author_id  inbound                      created_at  \\\n",
       "0         1  sprintcare    False  Tue Oct 31 22:10:47 +0000 2017   \n",
       "1         2      115712     True  Tue Oct 31 22:11:45 +0000 2017   \n",
       "2         3      115712     True  Tue Oct 31 22:08:27 +0000 2017   \n",
       "3         4  sprintcare    False  Tue Oct 31 21:54:49 +0000 2017   \n",
       "4         5      115712     True  Tue Oct 31 21:49:35 +0000 2017   \n",
       "\n",
       "                                                text response_tweet_id  \\\n",
       "0  @115712 I understand. I would like to assist y...                 2   \n",
       "1      @sprintcare and how do you propose we do that               NaN   \n",
       "2  @sprintcare I have sent several private messag...                 1   \n",
       "3  @115712 Please send us a Private Message so th...                 3   \n",
       "4                                 @sprintcare I did.                 4   \n",
       "\n",
       "   in_response_to_tweet_id  \n",
       "0                      3.0  \n",
       "1                      1.0  \n",
       "2                      4.0  \n",
       "3                      5.0  \n",
       "4                      6.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## read in data\n",
    "\n",
    "df_raw = pd.read_csv('twcs.csv', nrows=None)\n",
    "print(df_raw.info())\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "## clean data a bit and SAVE\n",
    "\n",
    "# convert 'created_at' to datetime format\n",
    "df = df_raw[['created_at', 'author_id', 'text', 'tweet_id', 'response_tweet_id', \n",
    "         'in_response_to_tweet_id', 'inbound']].copy()\n",
    "df['time'] = pd.to_datetime(df['created_at'], infer_datetime_format=True)\n",
    "\n",
    "# rearrange columns and sort by time\n",
    "df = df[['time', 'author_id', 'text', 'tweet_id', 'response_tweet_id', \n",
    "         'in_response_to_tweet_id', 'inbound']]\n",
    "df.sort_values(by = \"time\", inplace = True)\n",
    "\n",
    "# set tweet_id as index\n",
    "df.set_index('tweet_id', inplace = True)\n",
    "\n",
    "# standardize whitespace to avoid problems with saving as csv\n",
    "df[\"text\"] = df[\"text\"].str.replace(r\"\\s+\", \" \", regex = True)\n",
    "\n",
    "# save\n",
    "df.to_csv(\"twcs_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## destroy df_raw\n",
    "df_raw = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2811774 entries, 790341 to 589938\n",
      "Data columns (total 6 columns):\n",
      "time                       datetime64[ns]\n",
      "author_id                  object\n",
      "text                       object\n",
      "response_tweet_id          object\n",
      "in_response_to_tweet_id    float64\n",
      "inbound                    bool\n",
      "dtypes: bool(1), datetime64[ns](1), float64(1), object(3)\n",
      "memory usage: 131.4+ MB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>author_id</th>\n",
       "      <th>text</th>\n",
       "      <th>response_tweet_id</th>\n",
       "      <th>in_response_to_tweet_id</th>\n",
       "      <th>inbound</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>790341</th>\n",
       "      <td>2008-05-08 20:13:59</td>\n",
       "      <td>SouthwestAir</td>\n",
       "      <td>@34622 Have FUN at the lecture tonight! Tell P...</td>\n",
       "      <td>790326</td>\n",
       "      <td>790342.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790326</th>\n",
       "      <td>2008-05-08 21:04:16</td>\n",
       "      <td>308466</td>\n",
       "      <td>@SouthwestAir Can you pls enter the HI market ...</td>\n",
       "      <td>790327,790328,790325,790329,790330,790331,7903...</td>\n",
       "      <td>790341.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1757947</th>\n",
       "      <td>2010-02-16 15:49:47</td>\n",
       "      <td>529256</td>\n",
       "      <td>KTAR.com - Foreclosures still big problem in V...</td>\n",
       "      <td>1757946</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2291020</th>\n",
       "      <td>2010-03-31 15:24:29</td>\n",
       "      <td>665443</td>\n",
       "      <td>@665445 Do you know if Carl's Jr serves lunch ...</td>\n",
       "      <td>2291018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2291018</th>\n",
       "      <td>2010-03-31 16:53:27</td>\n",
       "      <td>CarlsJr</td>\n",
       "      <td>@665443 We serve lunch all day!</td>\n",
       "      <td>2291019</td>\n",
       "      <td>2291020.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        time     author_id  \\\n",
       "tweet_id                                     \n",
       "790341   2008-05-08 20:13:59  SouthwestAir   \n",
       "790326   2008-05-08 21:04:16        308466   \n",
       "1757947  2010-02-16 15:49:47        529256   \n",
       "2291020  2010-03-31 15:24:29        665443   \n",
       "2291018  2010-03-31 16:53:27       CarlsJr   \n",
       "\n",
       "                                                       text  \\\n",
       "tweet_id                                                      \n",
       "790341    @34622 Have FUN at the lecture tonight! Tell P...   \n",
       "790326    @SouthwestAir Can you pls enter the HI market ...   \n",
       "1757947   KTAR.com - Foreclosures still big problem in V...   \n",
       "2291020   @665445 Do you know if Carl's Jr serves lunch ...   \n",
       "2291018                     @665443 We serve lunch all day!   \n",
       "\n",
       "                                          response_tweet_id  \\\n",
       "tweet_id                                                      \n",
       "790341                                               790326   \n",
       "790326    790327,790328,790325,790329,790330,790331,7903...   \n",
       "1757947                                             1757946   \n",
       "2291020                                             2291018   \n",
       "2291018                                             2291019   \n",
       "\n",
       "          in_response_to_tweet_id  inbound  \n",
       "tweet_id                                    \n",
       "790341                   790342.0    False  \n",
       "790326                   790341.0     True  \n",
       "1757947                       NaN     True  \n",
       "2291020                       NaN     True  \n",
       "2291018                 2291020.0    False  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### ENTRY POINT. load clean csv\n",
    "\n",
    "df = pd.read_csv('twcs_clean.csv').set_index(\"tweet_id\")\n",
    "df[\"time\"] = pd.to_datetime(df[\"time\"], infer_datetime_format=True)\n",
    "print(df.info())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing convo_start_locs ...\n",
      "Total convos = 794335\n",
      "\n",
      "Example convo for \"sprintcare\":\n",
      "[['@115714 yâ€™all lie about your â€œgreatâ€ connection. 5 bars LTE, still wonâ€™t load something. Smh.']\n",
      " [\"@115713 H there! We'd definitely like to work with you on this, how long have you been experiencing this issue? -AA\"]\n",
      " ['@sprintcare Since I signed up with you....Since day 1']\n",
      " [\"@115713 We understand your concerns and we'd like for you to please send us a Direct Message, so that we can further assist you. -AA\"]\n",
      " ['@sprintcare You gonna magically change your connectivity for me and my whole family ? ðŸ¤¥ ðŸ’¯']\n",
      " ['@115713 This is saddening to hear. Please shoot us a DM, so that we can look into this for you. -KC']\n",
      " [\"@115713 Hi, my name is Shantel, I'm a resolution supervisor here with Sprint. Your issues was brought to my attention. 1/2 -ResolutionSup SR\"]\n",
      " [\"@115713 I would really like to work with you to have this resolved. Kindly send us a DM. I'm here for you! -ResolutionSup SR\"]]\n"
     ]
    }
   ],
   "source": [
    "## make tweet chains for individual conversations\n",
    "\n",
    "# save start_locs of convos\n",
    "# a convo starts when 'in_response_to' is nan\n",
    "def is_start_of_convo(rowtuple):\n",
    "    \n",
    "    # having a finite \"in_response_to_tweet_id\" \n",
    "    # means tweet is not convo starter\n",
    "    if np.isfinite(\n",
    "        getattr(rowtuple, \"in_response_to_tweet_id\")):\n",
    "        return False\n",
    "    \n",
    "    else:\n",
    "        return True\n",
    "    \n",
    "def get_start_locs(df = df):\n",
    "    \n",
    "    print(\"Computing convo_start_locs ...\")\n",
    "    \n",
    "    # get the starter tups\n",
    "    starter_tups_map = filter(is_start_of_convo,\n",
    "                             df.itertuples())\n",
    "    \n",
    "    # get the locs of the starter tups\n",
    "    tup_to_loc = lambda tup: tup.Index\n",
    "    start_locs = list(map(tup_to_loc, starter_tups_map))\n",
    "    \n",
    "    return start_locs\n",
    "    \n",
    "convo_start_locs = get_start_locs()\n",
    "        \n",
    "print('Total convos =', len(convo_start_locs))\n",
    "# print('convo_start_locs =', convo_start_locs)\n",
    "\n",
    "# get the locs (and company) for a conversation given a start_loc\n",
    "def get_convo_locs_n_comp(convo_start_loc, df = df):\n",
    "    \n",
    "    def get_next_locs(cur_locs, df = df):\n",
    "        # recursively gets next locs\n",
    "        \n",
    "        next_locs = []\n",
    "        for cur_loc in cur_locs:\n",
    "            \n",
    "            if cur_loc in df.index:\n",
    "                resp_tw_ids_entry = df.loc[cur_loc]['response_tweet_id']\n",
    "                \n",
    "                if isinstance(resp_tw_ids_entry, str):\n",
    "                    # next line splits up something like \"45,65\"\n",
    "                    # in the response_tweet_id into a list of locs: [45, 65]\n",
    "                    next_locs += list(map(int, resp_tw_ids_entry.split(\",\")))\n",
    "                    \n",
    "        if len(next_locs) > 0:\n",
    "            next_locs += get_next_locs(next_locs)\n",
    "        \n",
    "        return next_locs\n",
    "    \n",
    "    convo_locs = [convo_start_loc] + get_next_locs([convo_start_loc])\n",
    "    \n",
    "    # take out non-existent locs\n",
    "    convo_locs = list(filter(\n",
    "        lambda loc: loc in df.index,\n",
    "        convo_locs\n",
    "        ))\n",
    "    \n",
    "    # make df and sort by time\n",
    "    convo_df = df.loc[convo_locs]\n",
    "    convo_df.sort_values(by = 'time', inplace = True)\n",
    "    convo_locs = list(convo_df.index)\n",
    "    \n",
    "    # get company\n",
    "    company = np.nan\n",
    "    for rowtup in convo_df.itertuples():\n",
    "\n",
    "        try:\n",
    "            # if int, keep hunting\n",
    "            _ = int(getattr(rowtup, \"author_id\"))\n",
    "            \n",
    "        except:\n",
    "            # if not int, save\n",
    "            company = getattr(rowtup, \"author_id\")\n",
    "            break\n",
    "    \n",
    "    return convo_locs, company\n",
    "\n",
    "start_loc = 18\n",
    "convo_locs, company = get_convo_locs_n_comp(start_loc)\n",
    "print(\"\\nExample convo for \\\"\" + company + \"\\\":\")\n",
    "# print(df.loc[convo_locs][[\"author_id\", \"time\", \"text\"]])\n",
    "\n",
    "# temporary\n",
    "print(df.loc[convo_locs][[\"text\"]].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[([1757947, 1757946, 1757945], 'Ask_WellsFargo'),\n",
      " ([2291020, 2291018, 2291019], 'CarlsJr'),\n",
      " ([2651976, 2651975, 2651974, 2651973], 'JetBlue'),\n",
      " ([359955,\n",
      "   359954,\n",
      "   359953,\n",
      "   359960,\n",
      "   796821,\n",
      "   359981,\n",
      "   2163309,\n",
      "   359983,\n",
      "   2163310,\n",
      "   2163311,\n",
      "   2179300,\n",
      "   2163312,\n",
      "   359984,\n",
      "   2944620,\n",
      "   2944621,\n",
      "   2944622,\n",
      "   359957,\n",
      "   492818],\n",
      "  'AskPlayStation'),\n",
      " ([1985354, 1985353, 1985352], 'Ask_Spectrum')]\n",
      " ...\n"
     ]
    }
   ],
   "source": [
    "## SLOW! get convo_loc_lists for all start_locs\n",
    "\n",
    "# cll: convo_loc_list\n",
    "cll_comp_tups = list(map(get_convo_locs_n_comp, convo_start_locs))\n",
    "pprint(cll_comp_tups[:5])\n",
    "print(\" ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "### group convos by company\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "# making a dict where item is (company: clll)\n",
    "# clll: cll_list i.e. list of conversations (\"cll\"s)\n",
    "\n",
    "comp_clll_dict = defaultdict(list)\n",
    "\n",
    "for cll, comp in cll_comp_tups:\n",
    "    comp_clll_dict[comp].append(cll)\n",
    "    \n",
    "# comp_clll_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comp_cll_df.csv:\n",
      "          company                                           clll_str\n",
      "0  Ask_WellsFargo  1757947,1757946,1757945 2984140,2984139,298413...\n",
      "1         CarlsJr  2291020,2291018,2291019 2206745,2206744,220674...\n",
      "2         JetBlue  2651976,2651975,2651974,2651973 2631045,263104...\n",
      "3  AskPlayStation  359955,359954,359953,359960,796821,359981,2163...\n",
      "4    Ask_Spectrum  1985354,1985353,1985352 151800,151799,151798 1...\n"
     ]
    }
   ],
   "source": [
    "### tool to save comp_clll_dict to csv\n",
    "\n",
    "def save_locs_dict_to_csv(comp_clll_dict = comp_clll_dict):\n",
    "    \n",
    "    # [[1, 2], [3, 4, 5]] to \"1,2 3,4,5\"\n",
    "    def list_list_to_str(ll):\n",
    "        return \" \".join(\n",
    "            [\",\".join(list(map(str, l)))\n",
    "                for l in ll]\n",
    "            )\n",
    "        \n",
    "    clls_map = comp_clll_dict.values()\n",
    "#     cll = list(comp_clll_dict.values())[0]\n",
    "#     print()\n",
    "    \n",
    "    cll_strs = list(map(list_list_to_str, clls_map))\n",
    "    \n",
    "    # make df\n",
    "    comp_cll_df = pd.DataFrame({\n",
    "        \"company\": list(comp_clll_dict.keys()),\n",
    "        \"clll_str\": cll_strs\n",
    "        })\n",
    "    \n",
    "    comp_cll_df.to_csv(\"comp_cll_df.csv\", index = False)\n",
    "    \n",
    "    return \"comp_cll_df.csv\"\n",
    "\n",
    "print(\"comp_cll_df to csv:\")\n",
    "print(pd.read_csv(save_locs_dict_to_csv()).head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comp_clll_dict_len:\n",
      "108\n"
     ]
    }
   ],
   "source": [
    "### ENTRY POINT. tool to load comp_clll_dict from csv\n",
    "\n",
    "def load_locs_dict_from_csv(path = \"comp_cll_df.csv\"):\n",
    "    \n",
    "    # \"1,2 3,4,5\" to [[1, 2], [3, 4, 5]]\n",
    "    def str_to_ll(s):\n",
    "        clstrs = s.split(\" \")\n",
    "        cll = [s.split(\",\") for s in clstrs]\n",
    "        return cll\n",
    "    \n",
    "    # read csv\n",
    "    df = pd.read_csv(path)\n",
    "    comps = df[\"company\"].values\n",
    "    clll_strs = df[\"clll_str\"]\n",
    "    cllls_map = map(str_to_ll, clll_strs)\n",
    "    \n",
    "    # turn to dict\n",
    "    comp_clll_dict = dict(zip(\n",
    "        comps, cllls_map\n",
    "        ))\n",
    "    return comp_clll_dict\n",
    "\n",
    "comp_clll_dict = load_locs_dict_from_csv()\n",
    "print(\"comp_clll_dict_len:\")\n",
    "pprint(len(comp_clll_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
